1. Download latest Spark for current Hadoop. Decompress them to home director. 

cd ~/Downloads
tar zxvf spark-2.2.1-bin-hadoop2.6.tgz 
mv spark-2.2.1-bin-hadoop2.6 ~/


2. Setup SPARK_HOME and PATH variables in ~/.bashrc

vim ~/.bashrc
---------------------------------
# .bashrc
...

export SPARK_HOME=/home/cloudera/spark-2.2.1-bin-hadoop2.6
export PATH=$SPARK_HOME/bin:$PATH
export PYSPARK_PYTHON=python3
export PYSPARK_DRIVER_PYTHON=ipython3

3. source ~/.bashrc for the settings to take effect

source ~/.bashrc


4. Test it

[cloudera@quickstart ~]$ which spark-submit
~/spark-2.2.1-bin-hadoop2.6/bin/spark-submit

5. Start the spark cluster

cd ~/spark-2.2.1-bin-hadoop2.6/sbin
./start-all.sh

check http://localhost:8080

to see if the master and a worker are running

6. Setup spark-shell for Spark SQL

# allow cloudera user to access /tmp/hive locally and /tmp/hive in HDFS

sudo chmod 777 -R /tmp/hive

sudo su - hdfs
hadoop fs -chmod -R 777 /tmp/hive
exit

7. test spark-shell

pyspark --master spark://quickstart.cloudera:7077

Welcome to
      ____              __
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /__ / .__/\_,_/_/ /_/\_\   version 2.2.1
      /_/

Using Python version 3.6.5 (default, Jun  6 2018 20:18:28)
SparkSession available as 'spark'.


